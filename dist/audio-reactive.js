// audio-reactive.js — Generated by GAME compiler v0.2.0
// Zero-dependency WebGPU component with WebGL2 fallback.
//   <script type="module" src="./audio-reactive.js"></script>
//   <audio-reactive></audio-reactive>

const SHADER = `// Generated by GAME compiler v0.2.0
// https://github.com/runyourempire/game-engine

struct Uniforms {
    time: f32,
    audio_bass: f32,
    audio_mid: f32,
    audio_treble: f32,
    audio_energy: f32,
    audio_beat: f32,
    resolution: vec2f,
    mouse: vec2f,
    p_scale: f32,
    p_glow: f32,
}

@group(0) @binding(0) var<uniform> u: Uniforms;

struct VertexOutput {
    @builtin(position) position: vec4f,
    @location(0) uv: vec2f,
}

@vertex
fn vs_main(@builtin(vertex_index) vi: u32) -> VertexOutput {
    var pos = array<vec2f, 4>(
        vec2f(-1.0, -1.0),
        vec2f( 1.0, -1.0),
        vec2f(-1.0,  1.0),
        vec2f( 1.0,  1.0),
    );
    var out: VertexOutput;
    out.position = vec4f(pos[vi], 0.0, 1.0);
    out.uv = pos[vi] * 0.5 + 0.5;
    return out;
}

// ── Built-in functions ──────────────────────────────────

fn hash2(p: vec2f) -> f32 {
    var p3 = fract(vec3f(p.x, p.y, p.x) * 0.1031);
    p3 += dot(p3, p3.yzx + 33.33);
    return fract((p3.x + p3.y) * p3.z);
}

fn noise2(p: vec2f) -> f32 {
    let i = floor(p);
    let f = fract(p);
    let u = f * f * (3.0 - 2.0 * f);
    return mix(
        mix(hash2(i), hash2(i + vec2f(1.0, 0.0)), u.x),
        mix(hash2(i + vec2f(0.0, 1.0)), hash2(i + vec2f(1.0, 1.0)), u.x),
        u.y
    ) * 2.0 - 1.0;
}

fn fbm2(p: vec2f, octaves: i32, persistence: f32, lacunarity: f32) -> f32 {
    var value: f32 = 0.0;
    var amplitude: f32 = 1.0;
    var frequency: f32 = 1.0;
    var max_val: f32 = 0.0;
    for (var i: i32 = 0; i < octaves; i++) {
        value += noise2(p * frequency) * amplitude;
        max_val += amplitude;
        amplitude *= persistence;
        frequency *= lacunarity;
    }
    return value / max_val;
}

fn field_at(p: vec2f) -> f32 {
    let scale = u.p_scale;
    let glow = u.p_glow;
    let time = fract(u.time / 120.0) * 120.0;
    return fbm2((p * scale), i32(6.0), 0.5, 2.0);
}

fn map_scene(pos: vec3f) -> f32 {
    return pos.y - field_at(pos.xz);
}

fn calc_normal(pos: vec3f) -> vec3f {
    let e = 0.001;
    return normalize(vec3f(
        map_scene(pos + vec3f(e, 0.0, 0.0)) - map_scene(pos - vec3f(e, 0.0, 0.0)),
        map_scene(pos + vec3f(0.0, e, 0.0)) - map_scene(pos - vec3f(0.0, e, 0.0)),
        map_scene(pos + vec3f(0.0, 0.0, e)) - map_scene(pos - vec3f(0.0, 0.0, e))
    ));
}

@fragment
fn fs_main(input: VertexOutput) -> @location(0) vec4f {
    let uv = input.uv * 2.0 - 1.0;
    let aspect = u.resolution.x / u.resolution.y;
    let time = fract(u.time / 120.0) * 120.0;

    let scale = u.p_scale;
    let glow = u.p_glow;

    let cam_angle = time * 0.050000;
    let cam_pos = vec3f(cos(cam_angle) * 4.00, 2.00, sin(cam_angle) * 4.00);
    let target = vec3f(0.0);
    let forward = normalize(target - cam_pos);
    let right = normalize(cross(vec3f(0.0, 1.0, 0.0), forward));
    let up = cross(forward, right);
    let rd = normalize(forward + right * uv.x * aspect + up * uv.y);

    // Raymarch
    var t: f32 = 0.0;
    var hit = false;
    for (var i: i32 = 0; i < 128; i++) {
        let pos = cam_pos + rd * t;
        let d = map_scene(pos);
        if (abs(d) < 0.001) { hit = true; break; }
        t += d * 0.8;  // relaxation factor
        if (t > 50.0) { break; }
    }

    if (!hit) {
        let sky = mix(vec3f(0.0, 0.0, 0.05), vec3f(0.0, 0.0, 0.15), uv.y * 0.5 + 0.5);
        return vec4f(sky, 1.0);
    }

    let hit_pos = cam_pos + rd * t;
    let normal = calc_normal(hit_pos);
    let height = clamp(field_at(hit_pos.xz) * 0.5 + 0.5, 0.0, 1.0);

    let sun_dir = normalize(vec3f(0.5, 0.8, 1.0));
    let sun_intensity = 0.8;
    let ambient = 0.15;
    let ndotl = max(dot(normal, sun_dir), 0.0);
    let lighting = ndotl * sun_intensity + ambient;

    let albedo = mix(vec3f(0.0, 0.0, 0.1), vec3f(0.831, 0.686, 0.216), height);
    let emissive_color = select(vec3f(0.0), (vec3f(0.831, 0.686, 0.216) * glow), (height > 0.6));
    var color = albedo * lighting + emissive_color;

    // Distance fog
    let fog_amount = 1.0 - exp(-t * 0.03);
    color = mix(color, vec3f(0.0, 0.0, 0.05), fog_amount);

    // Post-processing
    let lum = dot(color, vec3f(0.299, 0.587, 0.114));
    color += max(lum - 0.7, 0.0) * 1.2;  // bloom
    color *= 1.0 - length(uv) * 0.3;  // vignette

    return vec4f(color, 1.0);
}
`;
const GLSL_VS = `#version 300 es
precision highp float;

uniform float u_time;
uniform float u_audio_bass;
uniform float u_audio_mid;
uniform float u_audio_treble;
uniform float u_audio_energy;
uniform float u_audio_beat;
uniform vec2 u_resolution;
uniform vec2 u_mouse;
uniform float u_p_scale;
uniform float u_p_glow;

out vec2 v_uv;

void main() {
    vec2 pos[4] = vec2[4](
        vec2(-1.0, -1.0),
        vec2( 1.0, -1.0),
        vec2(-1.0,  1.0),
        vec2( 1.0,  1.0)
    );
    gl_Position = vec4(pos[gl_VertexID], 0.0, 1.0);
    v_uv = pos[gl_VertexID] * 0.5 + 0.5;
}
`;
const GLSL_FS = `#version 300 es
precision highp float;

uniform float u_time;
uniform float u_audio_bass;
uniform float u_audio_mid;
uniform float u_audio_treble;
uniform float u_audio_energy;
uniform float u_audio_beat;
uniform vec2 u_resolution;
uniform vec2 u_mouse;
uniform float u_p_scale;
uniform float u_p_glow;

in vec2 v_uv;
out vec4 fragColor;






// ── Built-in functions ──────────────────────────────────


float hash2(p: vec2){
    float p3 = fract(vec3(p.x, p.y, p.x) * 0.1031);
    p3 += dot(p3, p3.yzx + 33.33);
    return fract((p3.x + p3.y) * p3.z);
}

float noise2(p: vec2){
    float i = floor(p);
    float f = fract(p);
    float u = f * f * (3.0 - 2.0 * f);
    return mix(
        mix(hash2(i), hash2(i + vec2(1.0, 0.0)), u.x),
        mix(hash2(i + vec2(0.0, 1.0)), hash2(i + vec2(1.0, 1.0)), u.x),
        u.y
    ) * 2.0 - 1.0;
}

float fbm2(p: vec2, octaves: i32, persistence: float, lacunarity: float){
    float value: float = 0.0;
    float amplitude: float = 1.0;
    float frequency: float = 1.0;
    float max_val: float = 0.0;
    for (int i = 0; i < octaves; i++) {
        value += noise2(p * frequency) * amplitude;
        max_val += amplitude;
        amplitude *= persistence;
        frequency *= lacunarity;
    }
    return value / max_val;
}

float field_at(p: vec2){
    float scale = u_p_scale;
    float glow = u_p_glow;
    float time = fract(u_time / 120.0) * 120.0;
    return fbm2((p * scale), int(6.0), 0.5, 2.0);
}

float map_scene(pos: vec3){
    return pos.y - field_at(pos.xz);
}

vec3 calc_normal(pos: vec3){
    float e = 0.001;
    return normalize(vec3(
        map_scene(pos + vec3(e, 0.0, 0.0)) - map_scene(pos - vec3(e, 0.0, 0.0)),
        map_scene(pos + vec3(0.0, e, 0.0)) - map_scene(pos - vec3(0.0, e, 0.0)),
        map_scene(pos + vec3(0.0, 0.0, e)) - map_scene(pos - vec3(0.0, 0.0, e))
    ));
}

void fs_main(input: VertexOutput){
    float uv = v_uv * 2.0 - 1.0;
    float aspect = u_resolution.x / u_resolution.y;
    float time = fract(u_time / 120.0) * 120.0;

    float scale = u_p_scale;
    float glow = u_p_glow;

    float cam_angle = time * 0.050000;
    vec3 cam_pos = vec3(cos(cam_angle) * 4.00, 2.00, sin(cam_angle) * 4.00);
    vec3 target = vec3(0.0);
    float forward = normalize(target - cam_pos);
    float right = normalize(cross(vec3(0.0, 1.0, 0.0), forward));
    float up = cross(forward, right);
    vec2 rd = normalize(forward + right * uv.x * aspect + up * uv.y);

    // Raymarch
    float t: float = 0.0;
    float hit = false;
    for (int i = 0; i < 128; i++) {
        float pos = cam_pos + rd * t;
        float d = map_scene(pos);
        if (abs(d) < 0.001) { hit = true; break; }
        t += d * 0.8;  // relaxation factor
        if (t > 50.0) { break; }
    }

    if (!hit) {
        vec3 sky = mix(vec3(0.0, 0.0, 0.05), vec3(0.0, 0.0, 0.15), uv.y * 0.5 + 0.5);
        fragColor = vec4(sky, 1.0);
    }

    float hit_pos = cam_pos + rd * t;
    float normal = calc_normal(hit_pos);
    float height = clamp(field_at(hit_pos.xz) * 0.5 + 0.5, 0.0, 1.0);

    float sun_dir = normalize(vec3(0.5, 0.8, 1.0));
    float sun_intensity = 0.8;
    float ambient = 0.15;
    float ndotl = max(dot(normal, sun_dir), 0.0);
    float lighting = ndotl * sun_intensity + ambient;

    vec3 albedo = mix(vec3(0.0, 0.0, 0.1), vec3(0.831, 0.686, 0.216), height);
    float emissive_color = ((height > 0.6) ? (vec3(0.831, 0.686, 0.216) * glow) : vec3(0.0));
    float color = albedo * lighting + emissive_color;

    // Distance fog
    float fog_amount = 1.0 - exp(-t * 0.03);
    color = mix(color, vec3(0.0, 0.0, 0.05), fog_amount);

    // Post-processing
    float lum = dot(color, vec3(0.299, 0.587, 0.114));
    color += max(lum - 0.7, 0.0) * 1.2;  // bloom
    color *= 1.0 - length(uv) * 0.3;  // vignette

    fragColor = vec4(color, 1.0);
}
`;

class AudioReactive extends HTMLElement {
  static get observedAttributes() {
    return [];
  }

  constructor() {
    super();
    this.attachShadow({ mode: 'open' });
    this._data = {  };
    this._device = null;
    this._ctx = null;
    this._pipeline = null;
    this._uniformBuffer = null;
    this._uniformData = null;
    this._bindGroup = null;
    this._animFrame = null;
    this._resizeObserver = null;
    this._startTime = 0;
    this._canvas = null;
    this._format = null;
    this._mouseX = 0.5;
    this._mouseY = 0.5;
    this._paramValues = new Float32Array(2);
  }


  attributeChangedCallback(name, _, newVal) {
    if (name in this._data) {
      this._data[name] = parseFloat(newVal) || 0;
    }
  }

  connectedCallback() {
    this._init();
  }

  disconnectedCallback() {
    if (this._animFrame) {
      cancelAnimationFrame(this._animFrame);
      this._animFrame = null;
    }
    if (this._resizeObserver) {
      this._resizeObserver.disconnect();
      this._resizeObserver = null;
    }
    this._device = null;
    this._pipeline = null;
    this._uniformBuffer = null;
    this._ctx = null;
  }

  async _init() {
    this.shadowRoot.innerHTML = `
      <style>
        :host { display: block; position: relative; background: #000; overflow: hidden; }
        canvas { display: block; width: 100%; height: 100%; }
        .fallback { display: flex; align-items: center; justify-content: center; width: 100%; height: 100%; color: #444; font: 11px/1 system-ui, sans-serif; text-align: center; }
      </style>
      <canvas></canvas>
    `;

    this._canvas = this.shadowRoot.querySelector('canvas');

    if (!navigator.gpu) {
      this._initWebGL2();
      return;
    }

    const adapter = await navigator.gpu.requestAdapter({
      powerPreference: 'high-performance',
    });
    if (!adapter) return;

    this._device = await adapter.requestDevice();
    this._device.lost.then((info) => {
      console.error('WebGPU device lost:', info.message);
    });

    this._ctx = this._canvas.getContext('webgpu');
    this._format = navigator.gpu.getPreferredCanvasFormat();

    this._resize();
    this._resizeObserver = new ResizeObserver(() => this._resize());
    this._resizeObserver.observe(this);

    const shaderModule = this._device.createShaderModule({ code: SHADER });

    const BUFFER_SIZE = 48;
    this._uniformBuffer = this._device.createBuffer({
      size: BUFFER_SIZE,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });

    const bindGroupLayout = this._device.createBindGroupLayout({
      entries: [{
        binding: 0,
        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,
        buffer: { type: 'uniform' },
      }],
    });

    this._bindGroup = this._device.createBindGroup({
      layout: bindGroupLayout,
      entries: [{ binding: 0, resource: { buffer: this._uniformBuffer } }],
    });

    this._pipeline = this._device.createRenderPipeline({
      layout: this._device.createPipelineLayout({
        bindGroupLayouts: [bindGroupLayout],
      }),
      vertex: {
        module: shaderModule,
        entryPoint: 'vs_main',
      },
      fragment: {
        module: shaderModule,
        entryPoint: 'fs_main',
        targets: [{ format: this._format }],
      },
      primitive: {
        topology: 'triangle-strip',
      },
    });

    this._uniformData = new Float32Array(Math.ceil(BUFFER_SIZE / 4));
    this._startTime = performance.now() / 1000;

    // Mouse tracking scoped to this element
    this.addEventListener('mousemove', (e) => {
      const rect = this.getBoundingClientRect();
      this._mouseX = (e.clientX - rect.left) / rect.width;
      this._mouseY = 1.0 - (e.clientY - rect.top) / rect.height;
    });

    this._frame();
  }

  _resize() {
    if (!this._device || !this._ctx || !this._format) return;
    const rect = this.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return;
    const dpr = window.devicePixelRatio || 1;
    this._canvas.width = Math.floor(rect.width * dpr);
    this._canvas.height = Math.floor(rect.height * dpr);
    this._ctx.configure({
      device: this._device,
      format: this._format,
      alphaMode: 'opaque',
    });
  }

  _frame() {
    this._animFrame = requestAnimationFrame(() => this._frame());
    if (!this._device || !this._pipeline || !this._uniformBuffer) return;

    const now = performance.now() / 1000;
    const time = now - this._startTime;
    const mouseX = this._mouseX;
    const mouseY = this._mouseY;

    // Apply arc timeline (override param bases)


    // Update param values
    this._paramValues[0] = (this._arcBaseOverrides?.[0] ?? 2) + (audioBass * 2.0);
    this._paramValues[1] = (this._arcBaseOverrides?.[1] ?? 0) + (audioEnergy * 0.8);

    // Write uniforms
    this._uniformData[0] = time;
    this._uniformData[1] = 0; // audio_bass (unused in component mode)
    this._uniformData[2] = 0; // audio_mid
    this._uniformData[3] = 0; // audio_treble
    this._uniformData[4] = 0; // audio_energy
    this._uniformData[5] = 0; // audio_beat
    this._uniformData[6] = this._canvas.width;
    this._uniformData[7] = this._canvas.height;
    this._uniformData[8] = mouseX;
    this._uniformData[9] = mouseY;

    for (let i = 0; i < 2; i++) {
      this._uniformData[10 + i] = this._paramValues[i];
    }

    this._device.queue.writeBuffer(this._uniformBuffer, 0, this._uniformData);

    const encoder = this._device.createCommandEncoder();
    const pass = encoder.beginRenderPass({
      colorAttachments: [{
        view: this._ctx.getCurrentTexture().createView(),
        loadOp: 'clear',
        clearValue: { r: 0, g: 0, b: 0, a: 1 },
        storeOp: 'store',
      }],
    });
    pass.setPipeline(this._pipeline);
    pass.setBindGroup(0, this._bindGroup);
    pass.draw(4, 1, 0, 0);
    pass.end();
    this._device.queue.submit([encoder.finish()]);
  }

  // ── WebGL2 Fallback ──────────────────────────────────────
  _initWebGL2() {
    const gl = this._canvas.getContext('webgl2');
    if (!gl) {
      this._canvas.style.display = 'none';
      const fb = document.createElement('div');
      fb.className = 'fallback';
      fb.textContent = 'WebGPU and WebGL2 not available';
      this.shadowRoot.appendChild(fb);
      return;
    }

    this._gl = gl;
    this._glMode = true;

    // Compile shaders
    const vs = gl.createShader(gl.VERTEX_SHADER);
    gl.shaderSource(vs, GLSL_VS);
    gl.compileShader(vs);
    if (!gl.getShaderParameter(vs, gl.COMPILE_STATUS)) {
      console.error('GLSL vertex error:', gl.getShaderInfoLog(vs));
      return;
    }

    const fs = gl.createShader(gl.FRAGMENT_SHADER);
    gl.shaderSource(fs, GLSL_FS);
    gl.compileShader(fs);
    if (!gl.getShaderParameter(fs, gl.COMPILE_STATUS)) {
      console.error('GLSL fragment error:', gl.getShaderInfoLog(fs));
      return;
    }

    const prog = gl.createProgram();
    gl.attachShader(prog, vs);
    gl.attachShader(prog, fs);
    gl.linkProgram(prog);
    if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
      console.error('GLSL link error:', gl.getProgramInfoLog(prog));
      return;
    }

    this._glProgram = prog;

    // Cache uniform locations
    this._glUniforms = {
      u_time: gl.getUniformLocation(prog, 'u_time'),
      u_audio_bass: gl.getUniformLocation(prog, 'u_audio_bass'),
      u_audio_mid: gl.getUniformLocation(prog, 'u_audio_mid'),
      u_audio_treble: gl.getUniformLocation(prog, 'u_audio_treble'),
      u_audio_energy: gl.getUniformLocation(prog, 'u_audio_energy'),
      u_audio_beat: gl.getUniformLocation(prog, 'u_audio_beat'),
      u_resolution: gl.getUniformLocation(prog, 'u_resolution'),
      u_mouse: gl.getUniformLocation(prog, 'u_mouse'),
    };

    // Cache dynamic param uniform locations
    this._glParamUniforms = [];
    for (let i = 0; i < 2; i++) {
      const name = 'u_p_' + ['placeholder'][0]; // Will be set per-param below
      this._glParamUniforms.push(null);
    }
    this._glParamUniforms[0] = gl.getUniformLocation(prog, 'u_p_scale');
    this._glParamUniforms[1] = gl.getUniformLocation(prog, 'u_p_glow');

    this._startTime = performance.now() / 1000;
    this._paramValues = new Float32Array(2);

    // Resize
    this._glResize();
    this._resizeObserver = new ResizeObserver(() => this._glResize());
    this._resizeObserver.observe(this);

    // Mouse tracking
    this.addEventListener('mousemove', (e) => {
      const rect = this.getBoundingClientRect();
      this._mouseX = (e.clientX - rect.left) / rect.width;
      this._mouseY = 1.0 - (e.clientY - rect.top) / rect.height;
    });

    this._glFrame();
  }

  _glResize() {
    const rect = this.getBoundingClientRect();
    if (rect.width === 0 || rect.height === 0) return;
    const dpr = window.devicePixelRatio || 1;
    this._canvas.width = Math.floor(rect.width * dpr);
    this._canvas.height = Math.floor(rect.height * dpr);
    if (this._gl) {
      this._gl.viewport(0, 0, this._canvas.width, this._canvas.height);
    }
  }

  _glFrame() {
    this._animFrame = requestAnimationFrame(() => this._glFrame());
    const gl = this._gl;
    if (!gl || !this._glProgram) return;

    const now = performance.now() / 1000;
    const time = now - this._startTime;
    const mouseX = this._mouseX;
    const mouseY = this._mouseY;



    this._paramValues[0] = (this._arcBaseOverrides?.[0] ?? 2) + (audioBass * 2.0);
    this._paramValues[1] = (this._arcBaseOverrides?.[1] ?? 0) + (audioEnergy * 0.8);

    gl.useProgram(this._glProgram);

    // System uniforms
    const u = this._glUniforms;
    gl.uniform1f(u.u_time, time);
    gl.uniform1f(u.u_audio_bass, 0);
    gl.uniform1f(u.u_audio_mid, 0);
    gl.uniform1f(u.u_audio_treble, 0);
    gl.uniform1f(u.u_audio_energy, 0);
    gl.uniform1f(u.u_audio_beat, 0);
    gl.uniform2f(u.u_resolution, this._canvas.width, this._canvas.height);
    gl.uniform2f(u.u_mouse, mouseX, mouseY);

    // Dynamic param uniforms
    for (let i = 0; i < 2; i++) {
      if (this._glParamUniforms[i]) {
        gl.uniform1f(this._glParamUniforms[i], this._paramValues[i]);
      }
    }

    // Draw fullscreen quad (triangle strip, 4 vertices)
    gl.clearColor(0, 0, 0, 1);
    gl.clear(gl.COLOR_BUFFER_BIT);
    gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
  }
}

customElements.define('audio-reactive', AudioReactive);
export { AudioReactive };
export default AudioReactive;
